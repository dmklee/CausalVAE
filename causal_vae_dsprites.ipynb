{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.distributions.constraints as constraints\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pyro\n",
    "from pyro.contrib.examples.util import print_and_log\n",
    "import pyro.distributions as dist\n",
    "\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
    "from pyro.optim import Adam, SGD\n",
    "\n",
    "# Change figure aesthetics\n",
    "%matplotlib inline\n",
    "sns.set_context('talk', font_scale=1.2, rc={'lines.linewidth': 1.5})\n",
    "\n",
    "USE_CUDA = True\n",
    "\n",
    "pyro.enable_validation(True)\n",
    "pyro.distributions.enable_validation(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, image_dim, label_dim, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.image_dim = image_dim\n",
    "        self.label_dim = label_dim\n",
    "        self.z_dim = z_dim\n",
    "        # setup the three linear transformations used\n",
    "        self.fc1 = nn.Linear(self.image_dim+self.label_dim, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.fc31 = nn.Linear(1000, z_dim)  # mu values\n",
    "        self.fc32 = nn.Linear(1000, z_dim)  # sigma values\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, xs, ys):\n",
    "        # define the forward computation on the image xs and label ys\n",
    "        # first shape the mini-batch to have pixels in the rightmost dimension\n",
    "        xs = xs.reshape(-1, self.image_dim)\n",
    "        #now concatenate the image and label\n",
    "        inputs = torch.cat((xs,ys), -1)\n",
    "        # then compute the hidden units\n",
    "        hidden1 = self.softplus(self.fc1(inputs))\n",
    "        hidden2 = self.softplus(self.fc2(hidden1))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc31(hidden2)\n",
    "        z_scale = torch.exp(self.fc32(hidden2))\n",
    "        return z_loc, z_scale\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, image_dim, label_dim, z_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        # setup the two linear transformations used\n",
    "        hidden_dim = 1000\n",
    "        self.fc1 = nn.Linear(z_dim+label_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, image_dim)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, zs, ys):\n",
    "        # define the forward computation on the latent z and label y\n",
    "        # first concatenate z and y\n",
    "        inputs = torch.cat((zs, ys),-1)\n",
    "        # then compute the hidden units\n",
    "        hidden1 = self.softplus(self.fc1(inputs))\n",
    "        hidden2 = self.softplus(self.fc2(hidden1))\n",
    "        hidden3 = self.softplus(self.fc3(hidden2))\n",
    "        # return the parameter for the output Bernoulli\n",
    "        # each is of size batch_size x 784\n",
    "        loc_img = self.sigmoid(self.fc4(hidden3))\n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, config_enum=None, use_cuda=False, aux_loss_multiplier=None):\n",
    "\n",
    "        super(CVAE, self).__init__()\n",
    "    \n",
    "        self.image_dim = 64**2\n",
    "        self.label_shape = np.array((1,3,6,40,32,32))\n",
    "        self.label_names = np.array(('color', 'shape', 'scale', 'orientation', 'posX', 'posY'))\n",
    "        self.label_dim = np.sum(self.label_shape)\n",
    "        self.z_dim = 50                                    \n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        # define and instantiate the neural networks representing\n",
    "        # the paramters of various distributions in the model\n",
    "        self.setup_networks()\n",
    "\n",
    "    def setup_networks(self):\n",
    "        self.encoder = Encoder(self.image_dim, self.label_dim, self.z_dim)\n",
    "\n",
    "        self.decoder = Decoder(self.image_dim, self.label_dim, self.z_dim)\n",
    "\n",
    "        # using GPUs for faster training of the networks\n",
    "        if self.use_cuda:\n",
    "            self.cuda()\n",
    "\n",
    "    def model(self, xs, ys):\n",
    "        \"\"\"\n",
    "        The model corresponds to the following generative process:\n",
    "        p(z) = normal(0,I)              # dsprites label (latent)\n",
    "        p(x|y,z) = bernoulli(loc(y,z))   # an image\n",
    "        loc is given by a neural network  `decoder`\n",
    "\n",
    "        :param xs: a batch of scaled vectors of pixels from an image\n",
    "        :param ys: a batch of the class labels i.e.\n",
    "                   the digit corresponding to the image(s)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # register this pytorch module and all of its sub-modules with pyro\n",
    "        pyro.module(\"cvae\", self)\n",
    "\n",
    "        batch_size = xs.size(0)\n",
    "        options = dict(dtype=xs.dtype, device=xs.device)\n",
    "        with pyro.plate(\"data\"):\n",
    "\n",
    "            prior_loc = torch.zeros(batch_size, self.z_dim, **options)\n",
    "            prior_scale = torch.ones(batch_size, self.z_dim, **options)\n",
    "            zs = pyro.sample(\"z\", dist.Normal(prior_loc, prior_scale).to_event(1))\n",
    "            \n",
    "            # if the label y (which digit to write) is supervised, sample from the\n",
    "            # constant prior, otherwise, observe the value (i.e. score it against the constant prior)\n",
    "    \n",
    "            loc = self.decoder.forward(zs, self.remap_y(ys))\n",
    "            pyro.sample(\"x\", dist.Bernoulli(loc).to_event(1), obs=xs)\n",
    "            # return the loc so we can visualize it later\n",
    "            return loc\n",
    "\n",
    "    def guide(self, xs, ys):\n",
    "        \"\"\"\n",
    "        The guide corresponds to the following:\n",
    "        q(z|x,y) = normal(loc(x,y),scale(x,y))       # infer latent class from an image and the label \n",
    "        loc, scale are given by a neural network `encoder`\n",
    "\n",
    "        :param xs: a batch of scaled vectors of pixels from an image\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # inform Pyro that the variables in the batch of xs are conditionally independent\n",
    "        with pyro.plate(\"data\"):\n",
    "            # sample (and score) the latent handwriting-style with the variational\n",
    "            # distribution q(z|x) = normal(loc(x),scale(x))\n",
    "    \n",
    "            loc, scale = self.encoder.forward(xs, self.remap_y(ys))\n",
    "            pyro.sample(\"z\", dist.Normal(loc, scale).to_event(1))\n",
    "            \n",
    "    def remap_y(self, ys):\n",
    "        new_ys = []\n",
    "        options = dict(dtype=ys.dtype, device=ys.device)\n",
    "        for i, label_length in enumerate(self.label_shape):\n",
    "            prior = torch.ones(ys.size(0), label_length, **options) / (1.0 * label_length)\n",
    "            new_ys.append(pyro.sample(\"y_%s\" % self.label_names[i], dist.OneHotCategorical(prior), \n",
    "                                   obs=torch.nn.functional.one_hot(ys[:,i].to(torch.int64), int(label_length))))\n",
    "        new_ys = torch.cat(new_ys, -1)\n",
    "        return new_ys.to(torch.float32)\n",
    "            \n",
    "    def reconstruct_image(self, xs, ys):\n",
    "        # backward\n",
    "        sim_z_loc, sim_z_scale = self.encoder.forward(xs, self.remap_y(ys))\n",
    "        zs = dist.Normal(sim_z_loc, sim_z_scale).to_event(1).sample()\n",
    "        # forward\n",
    "        loc = self.decoder.forward(zs, self.remap_y(ys))\n",
    "        return dist.Bernoulli(loc).to_event(1).sample()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data_loaders(train_x, test_x, train_y, test_y, batch_size=128, use_cuda=False):\n",
    "    train_dset = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(train_x.astype(np.float32)).reshape(-1, 4096),\n",
    "        torch.from_numpy(train_y.astype(np.float32))\n",
    "    )\n",
    "    \n",
    "    test_dset = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(test_x.astype(np.float32)).reshape(-1, 4096),\n",
    "        torch.from_numpy(test_y.astype(np.float32))\n",
    "    )    \n",
    "    kwargs = {'num_workers': 1, 'pin_memory': use_cuda}\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dset, batch_size=batch_size, shuffle=False, **kwargs\n",
    "    )\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dset, batch_size=batch_size, shuffle=False, **kwargs\n",
    "    )\n",
    "    \n",
    "    return {\"train\":train_loader, \"test\":test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_zip = np.load(\n",
    "    'dsprites-dataset/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz',\n",
    "    encoding = 'bytes',\n",
    "    allow_pickle=True\n",
    ")\n",
    "imgs = dataset_zip['imgs']\n",
    "labels = dataset_zip['latents_classes']\n",
    "label_sizes = dataset_zip['metadata'][()][b'latents_sizes']\n",
    "label_names = dataset_zip['metadata'][()][b'latents_names']\n",
    "\n",
    "# Sample imgs randomly\n",
    "indices_sampled = np.arange(imgs.shape[0])\n",
    "np.random.shuffle(indices_sampled)\n",
    "imgs_sampled = imgs[indices_sampled]\n",
    "labels_sampled = labels[indices_sampled]\n",
    "\n",
    "data_loaders = setup_data_loaders(\n",
    "    imgs_sampled[1000:],\n",
    "    imgs_sampled[:1000],\n",
    "    labels_sampled[1000:],\n",
    "    labels_sampled[:1000],\n",
    "    batch_size=256,\n",
    "    use_cuda=USE_CUDA\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c81c28cbf94e94b5511de27cef2450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='shape', max=2), IntSlider(value=4, description='scale', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.find_in_dataset(shape, scale, orient, posX, posY)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_names = ['shape', 'scale', 'orientation', 'posX', 'posY']\n",
    "y_shapes = np.array((3,6,40,32,32))\n",
    "img_dict = {}\n",
    "for i, img in enumerate(imgs_sampled):\n",
    "    img_dict[tuple(labels_sampled[i])] = img\n",
    "    \n",
    "def find_in_dataset(shape, scale, orient, posX, posY):\n",
    "    fig = plt.figure()\n",
    "    img = img_dict[(0, shape, scale, orient, posX, posY)]\n",
    "    plt.imshow(img.reshape(64,64), cmap='Greys_r',  interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    \n",
    "interact(find_in_dataset, shape=widgets.IntSlider(min=0, max=2, step=1, value=npr.randint(2)),\n",
    "                          scale=widgets.IntSlider(min=0, max=5, step=1, value=npr.randint(5)),\n",
    "                            orient=widgets.IntSlider(min=0, max=39, step=1, value=npr.randint(39)),\n",
    "                            posX=widgets.IntSlider(min=0, max=31, step=1, value=npr.randint(31)),\n",
    "                            posY=widgets.IntSlider(min=0, max=31, step=1, value=npr.randint(31)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAE0CAYAAADOq1/fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHlxJREFUeJzt3XmYJFWZqPH3A6QRUBQZlBGlWRRcRhEBwQVbcVRUXEZGmXGE5joqMO7jPiI4KqijiCh3EBDQK3AFVBAUcRkbZVMRUa4KytKyCwgKNN3N9t0/zkkqiI6szKrK6qrufn/Pk09WxXLiZJzM+CLOOXEiMhNJ0qpttZnOgCRp5hkMJEkGA0mSwUCShMFAkoTBQJLEBIJBROwYEcdFxMKIWBoRt0fEFRHx/YjYPyKe3Fp+XkRkRCwYea5XUBGxTUS8NyJOjIgr6/7J9r4b4fbWqds7LyL+EhF3RcQNEfGriPhSRMyPiNWnY9sD8nVA/dwHLO9tt/Lx1og4OSIujYhbI+Luun9Oj4iXTeN2t6/7/7KIWFR/S7+LiM9HxJZTTHtW7NuZEBFz62dfONN5maiIeFBE/H1EHBIRF0XEHfU4e2X9rjxhwPo7RcSpEXFTXW9hRBwWEY8cOhOZOfAFvAe4D0jgD8C3gOOBnwCL6vRPt9aZV6cvGGYbq8ILOKXuk/brydOwrb8FLq3pLwZ+BJwAnApc3tj2ujOwHw6o2z5ghsvjGmApcEH9Tp9Y/+7tm4NHvL3VgcMa6V8KnAR8A1hYp90NvH9F3rfA/JqHY0ec7rE13fl95s+t8xfO5Pdqkp/tBY3vxdX1WPF14Mo6bQnwij7rvqVxfP55a70/AY8fJg9r9I0SVURsDXwSuAd4XWae1Jr/YOClwJxBaYnzgIuBX1AOOmcDm0zTtg4DHg/8APinzLy5OTMiHg+8Abh3mra/Ingt8MvMvLM5MSKeDXwXeGdEnJSZ541oe0cA/wu4CdgjM7/b2u7uwFHAQRERmXnQJLbxBeD/AjcPWnAldC3wBEpAXdHcRzkxODgzz+9NrFfuHwfeB3w5IjbPzD835m8NHFLXf3VmnlqnrwF8HtgbOCEits0aOfoaImJ9jBJhjptgpJuHVwaD9tFCpuHKAHgw5QeRwONm+nN25O8AZsGVwYA8HlXz+OERpbdrTW8p8LRxlntxXe4e4CkzvR8m+VnnMwNXBivrCwjgkvrZ92jNO6JOP7pjvbUoV78JvGTQdoZpM9iwvt84xLKdImJORHyk1pEujYhrat3YOh3LbhgR74iI79V6ryW1PvfHEbFHn/Tvb5+o9eT/VevaltQ0PhURDxknf8+KiJMi4rpGvfqJNequiB4O91/1TbjcImK1iHhdbQ+6uZbZ1RHxnYh4XWvZJ0XER2u7xPWN/ffNiHjWZDI/S8rjnvq+dETpva++H56Zv+y3UJarhVMoVUrvbs5rtgdExOYR8dW6z++NiHe0l+lKfyL7tlkHX78T74iI39Tf1Z8i4uiI2LC1zgLgmPrvnjHWLpYRcWxjuWdExGci4hcRcWPjO/bV6GhDi4gE9qz/HtNKd347v30++1OitHteWz/7n8b7ntbPnTXdl0TET6K079wWEd+NiG261hu1LEf2X9d/H92avW19/2HHekuAc+q/rxxmQ4Oi0ocYq8faaALRbF5d71xgAXAr5Uv+beC2Ou/MjvX+pc77I6WK4wTgx5QfZwKHDdjWT4HbKXXjXwduqfMupKN+nPIjvY9SXfJTHlhvvBTYdZwzlCmd+TB9VwZrAnfWtPeb4LpzahklcFctu+Pr+y206mMpZ9D3Af+vrncS8CvGzm5379jGAfS5MpjJ8mikt3X9vt7LCM7OgUcwVqf79CGW/4e67J+B6Nhvx9f8XQV8DTgdeNOo9y2NOnjgOEr74Lcpv+Ob6ryLgTmNdd5Pqf5M4LJaNr3XvzaW+wHl6vUiym/1G4y1cd0J7NRRxpfV+We30n12O7999unSOv+iug/Pq//fC+wzzu/zoLrMT+o+6+XjDjrq40f9faxpXljT3Ks1/fd1+i591vvfdf7PB25jiExsUj901i/DicDbgGcBa42z3jzGGkTOBR7emLc58Jc6r13oTwC260hvc0qASGCHcbb1W+BRjXnrAz+jo0GQ0tbRCzzbtObtWr+sfwHWn47CZpqCQU37C419cjGl3Wc3YO6A9T5f1/k1sGlr3pz2lw54LrBJRzovoQSTW4C1W/MOoOOANVPlAexT0zihflfvoxw43jyistiZsQPuGkMs/9hG2W3Wsd8SOBJ4UMe6I9u3jB1ck3LQeUxj3obAFXRXXcwfVB6U6rANO6b/a133dzQCYauc5/dJs5ffha3pGzF2Avrm1rxXUU5a7qYV+Bn7fS4GntuY/iDgm/SvnpnS97EjvV7j8hJaJ+SUM/8E9u2z7hl1/s0DtzNkZp7DWDRsvpZSemHs2LHOPMai7hM75vcOVvtPYKe8sa7zX322lXTUjQHPqPNuBx7cmN4LEs/rs71D6/y3taYfRKnDO2iKhdz7sk1HMJhDOSu4h2XL7QrKFd86rXUeSTmA303jIDSFPBxXt/fS1vQD6D5gzUh5UBpcm/tnEfAmYPURlcVra7rXT6DsennZvmO/3UyfXmCj3Lc8MBi8uGOdd9d5x7Smz2dqwbl3gHtSa/qxTC4YfLhO/36f9XrpHtWa3vt9fqJjnW3rvCs75o3k+FDT2oCxk+CPdczvtelewLLBc/P6e05g6aBtDXWfQWb+BNiKcrZ3COXsaTGlOmJX4OyIeHOf1a/KzN92TL+0vv9te0aUPre71HaGwyPimFrfuFtd5PF9tnVrZn6nI/8/pQSzdYFt6jY2ALaj/LAW9Envx/V9h1Z6H8jMrTLzA33Wm3GZuTQz9wU2Bd5BqTJbWGdvCnwUOD8iHt5Y7fmUs54FmXnFsNuKiPVqG8OnIuLIiDi2llev7rdfeTXTmLHyyMzdMzMo34+nUa5+vwicERFrTybNKYoB83+QmXcMndgU9m11N6Vap63vb3jIfG0YEW+obQdHNb43j6qLDPzeDGmn+v7lPvOPru/P7TP/jI5pfT/7qI4PEbEW5Xf7WEr5fKRjscMoVYZPB06MiCdGxLoR8TzgO4x9l+4btL2BXUt7MvMeyk45o5HRF1GqH7YEDo2I72Tm1a1V2//33F7fH9AlNSK2otQhjvdFeGif6X8cZ52FwBbAxvX/Tev7BsB9EeP+/v5mvJmzWS2Pz9UXEbE58G/A2ykH6wMp1SRQvnQw9kUfKCJeRfkxPWycxfqVV9OMl0dmLqLUJ+8VEfdRuoG+h+4f4UT0ugKuHxFr1N/SeJqNsl1dRMf7nneZ6r69oU+eO3/Dw4iIfYHPUHq89DPM92YYvUbXK/vMv6K1XNsyx7DMvL3uxzWnlrVuUbqGnkgJZBcCL8/MZbrMZub1EbErpc1lN8ZOmAGuo1wVHUiprh3X0MGgIxNLgFMj4ueUG9HWptQDHtladGBEajmZEghOoQSaS4HbMvPeiHghcCaDz5yG0bvz9hbgtAHLXjKC7c0KmXk58K6IWI0SEF7OWDDIiaQVEY+hNMStRekLfQIl6N6ZmRkRBwIfYLjymm3l8WVKMHgFUw8Gv6Ts2zUpjdMXDFh+u/p+K90HsMUT3P5U9+1Ef8PjiojtKNXE9wDvojSAX5OZi+v844F/YjS/81EY6ecfJMq9BcdRal1+B7woM//ab/nMPKee5L2G8v1ag9Lmd0KdBqWDx7gmHQwaGbkuIi6hVL9M6YytXhU8iXLX3G6Z2b4haosBSWwyzry59f3a+t6L9ndm5vwJZHNl8UNKMGiW2VX1fdjL85dSAsHXM/NDHfMHlVfTbCuPm+r7lK9CMvPPEXE+sCPwegYHg9fX9+9krfydotm2b19NOdAfmpmf7Zg/ke/NMK6lVHNvxlhXy6bNGsvNqCiXG1+iHMQvB16QrRtGu9Rqw6Pb0xvdZpfpeto2sM0gBlxT1ijWuwy9ZlB6A6xf36/vCAQAuw9Y/+ER8eL2xHomsgWlYfBCgMy8lhItN46IZ0w+y7PPoDKrHlffm2X2I0r98PMiYtNlV1lGr7yWuYyu9dR/P0QawKwsj3n1/bIRpfep+r53RDyt30L1+/sKSseLT49iwzOwb++q7/1ONsf73mxFabeZTLr99NpDOu9TAvaq72dNMN3p8AXK/RRXAc/PzOsmm1BEbEypNlpMaSQf1zANyB+LiIOjY6CkKDdyHUm5yekOuhtaJuIPlEuyJ0fEcxrbiYj4IKVX0yCfjsbgTBHxMEpPCYAv5QOHHvhwfT8hIpZpPIqINSNi1/oFbU4/KCIuiYjJDBcwYVFuppvI4GPrRcQFEbF7lOFC2uk9B9iv/ntib3pm/olyR+MawDciYpPWenMiYpfGpF6Vwqtb+3wdyv0H47UjdFlu5RHl5quXRMdAfbUO9uP136M65vduRpo/7PYy8xTgK5SqojMj4kUd6e5OqSaF0hvoomHTH8Kk9u0k9c6w+w2u1vve7BER6zbysAHlhrV+B/tB6fZzJOX49IKIeGNzRkS8nHJv0z2MHSemZLLHh4j4FLAvpa7/+Zl51YBVeuttW6t9m9M2o1QJrgP8R2YOvPl0mAi7DqU64Z1R7uy7mNJw9ChK96qHUrqYzs/Mm/olMozMvCkiDqfskB9FuZvxJkpL+WaUM6V390+B8yn1o3+IiP+hFPDzKGciv6J0p2xu75sR8T5KV7AFEfFbSn/qJZTGpKdRepjswgPrUjeiNJpvNJHPFxEvZewg3EsH4LiI6NUDX1h7ATX1CnoiY648nVJnuDgiLqRcAcyhXCH1evmcRelV1PRuylXDC4HfR8Q5wA01r0+l9NeeW5c9jbJfn1qXXUDZ5ztRgvoxjJ11DbScy+NxNX+31P1zIyV4bUnpkgdwSGYe17HuZMoDylhQSyjdVr8bEZdS6nZXp5TXJpQrgv0y82MTTHtcU9i3k3E+5TuzTURcAPyGsq/OycxjKPv9nZSq5csj4mxKL7Z5lAPhKXTfMXsqJai9I8pdyr2hFo7OzHP7ZaY2su5J+T0cERH7UOri5wLPrGn8W2b+ul8aEzTh72MNSu+p/14B7NfnAv/szGyfoJwMzImIiykdDjamVEmuQemG31UVt6wh+rk+gtKYczSlIewGSsHeRul58Vlg84715lF28oI+6c6noy8y5Ye2L+Ugs6h+uNPrh+tMszmd8oU+mNLjYinlcuvTwEPH+YzbUC6jrqT8OP5K+UGcCLyOZfvjH9uV9yH2Ze8zj/dqf7bVKQ2JS+i4uavPdoJyb8V/AN+nVHUsqvvjmro/Xw+s1mf91SkH8QV12739eDqtO4opJwMHU67qltT0v0Q5wBxAd5/3zunLszwY6157Vs3zEsqdr5dRzuCf02e9DSiB7kbgIRMp/0YaO1AOiJfXbd5RP99hwBPGWW/c/TbqfcuAUUAZ5zdOOUE4ndKT6t52+VBOJr9E6XCwpObns5SA3CvP+R3p7kYJNrcz9puZP2R+n0rp8HA9pcrpJkrgeXaf5RfW9Ob2mZ9AdkyfzPdxPoOPDZ1pUu4sP6d+nrvq5zuZxo1yw7yiJrZCi4h5lPruszJz3szmZrRqHe/5wGcz810znZ9VXUS8lnKT2tszcyTVCtJs4JPOZr+dKVdhHx+0oJaLnSlnsYfPdEakUfLKQJLklYEkaSW5MpAkTY1XBpIkg4EkyWAw4xp3szZfd9Y7GD9XbylfnvlZvd69nBHRNd5Qb7lX1mWuiwcOgz3Z7a4TZRjsQyLinIhYVNM/ecB68zv2X/O1ZKp5a2xrbp9t3BYRP4uI90UZzXe5iIj96/Z/2nUndWO5p0XE3RGxOCK2nOI2HxIRr4+IQyPi3JpmRsRXB6y394By+stU8qWpm/JAdRqZMyk39EG5IWcHyhPl/iUi5mXmxcsjE1lGh90L+AXlLshvZuZvmstExPrAf9d/987MW0ew6ccB4x5QBric8jjEtoneJTys3tj4q1FuYNuRMtroa2p53d53zdE5kHKn7vbAvzM2/tH9ogyFfDTlt/7+zBx6ePI+nkS5KW+yfk953GTbnR3TtDxN5g5KX6N7MXaX47zW9EdSDsgJnDcD+dq/bvuntJ74BfyfOu/4EW5vc8odqftQDm5vrts4ecB68xnhIwYHbGsu/e86fTrlbt5kBE+4mkCenkq563QxsGXH/P1qns6lzx3nE9zeVpSxfvamDEfztpr+Vwest3dd7vDltW98TexlNdEslWXQuN4dxztExKSeJjUFB1LGzdm+kQ8i4mWUgb1upBwIRiIzL8/MN2Tmf2fmzyhDYKwwMvMXlGE5oAzRvLy2+yvKDYlrAcc0Byyr4/d8iDLcw16ZOeVx+TPzksx8Y2YenpkXMDaSqFZwBoPZ7cLG3+0RRDeNiCNqm8PSiPhzRJxZD9bLiIiHRcSHIuJXEXFrreu9OiK+FxFvai+f5alKe1EGnvvPiNgyygiwX6yLvCWHGGd9FdMrr2WeqxERz4mIUyLixoi4KyKujYiv1gP2MiJii4j4YkRcWttPbouIyyPiaxGxc2vxAyljee1IGQCuN7T80ZRRUvfLqVcPaSVnm8Hs1nzs3/1nyhHxTMpw4Q+lDBD3DUo7w87ACyPiE9l4/mqUIaXPo1zi30AZ330xZTC57SiPuzyivfHMvDDKsLofpBxYLqM88/XrmXlSV4YjYi5jT+faNDMXTvAzT9YWUZ6s9jeUwfV+DpyW5Yl8y0uvvB5wVRMRb6U8djQo5bAQeCJlYLjdIuI1mfmtxvJPoQw8ti7wW0pZB/AY4FWUz3f/w0oy8+4ow2n/DPhoRHwL+AdK2Z7H2BVLM09bUUbuBNgoM29oLzNNtooytPMjKJ/jZ5Ry8gpjps10PdWq/qJPm0Gdt0+dtwR4cJ22FuWhIEmpHojG8s9kbDTHXRrT96zTTgPWaG1jDrDTOPmbQxmCuDdq4s3AI8dZfm5j2blT2C/zmVibQderNy78qMrq/s/WZ/7X6vwfN6ZtTbm6ugt4WWv5t9Tl/9rcp5QRTRN4X8c21ge26bP9A+p6v6QE+852hLrsVo399Kgp7JNeW8CwbQZdr6vpM0qsr+X3sppoFoqIR9aqm0/WSUdnfT4s5XF4G1OeDb1f1l8aQJYx3T9T//33RpK9B6z/MFsPNs/MpZn5Y/rIzKWUs9qe/bO0Z/Rzd83bpUxfT56m6ylDUW9LOVA+Angu5cx5I+D0iNh6ujYeEavVKrtPM/a82S80FnkbZUjwL2fm6c11M/MLlCG0Hwo0H7rSK68z29vLzFsy88L29OrjlOqirSknDeNVDy1lrJy6HnY/atdSgtXTKQ/D2gB4PuUqdWPgjIh44nLIh/qZ6Wi0qr8YuzLo9/o6sFZj+aPq9A/1Se+xdf5iai8gygN+emfK/wysN4H8rdvK41k0rkamcb/MZ4grgwFpnFjT+PaI8jR3QFndA3ywtc5ldV6/MfP3qPO/35j2EcZ6AO0MrDmBPL6srvsnRtB7aIjtDXVlMM76QXloTVKqH6c1v776v2wzmD169xn0qoWuAr6XpZdK06Pr+5V0u4ZSJbEW5Sz5xsz8Ua2nfS9wHHBfRPyOcmD/Wo5zZUC5OtmEUm+9BeUpZnszdp/BbPZR4B8pjzt8UJZG8VHp3WeQlIfTXAqcmpnt5/oOKq8rWstBuV9ge+DFwA+ApRHxC+B/gK9k5h/Gydcd9X1xjqD30HTLzIyIjwEvB14cEZE1Smj5MhjMHp/IzAXTlXhmfjAijgB2pVyeP5vyRLl9I+Irmblne50oz8rdh1Kn/UZKMPgR8MmIOL3jwDfb9KpI1qRUS1w/qoQzc/6o0upIexGwS0RsC7yUUu21A6VN6AMRsU9mHjld258BvXJam/Kks1HcxKgJss1gxdN7KPhmfeZvTDn4LQFuac7IzIWZ+fnMfBWlXvpFlB/eHtF6QHtErE25CSyAd2fmtZl5FqVr6UMY62I6m63f+PuOvktNr0HltVlruftl5gWZ+ZHMfD7ls7yd8ps9NCLWG3lOZ06znBbNWC5WcQaDFU+vSud1zRuMGnoPoD8nW43FTVl8j/KsVICntBb5OOWu4B/mAx/A/V5K749dIuL1E8798vWP9f33uXyGh+jSK689+szvlddZ4yWSmUuyPGbzMkoV4ONHk71ZoVdOv067mM4Yg8GK5yTKWeSWwEciInozojwvudeL6ODG9FdFxLOby9bp61Gqi6C0UfSm70jpBbOIB/ZyoR5U31z//WxEbNicHxGPjjLI3iUR0awHH7mIWDsi9qn3UbTn/TNwUP33cx3zD6gDpC2YzjwCh1IeCL9nRLyklYd9KA+Vv43SMaA3fd+IeFw7oYj4O0r7zX2UtqFJqz2geuW0wVTSGmJb60XEG+vVZnN6RMSewH/WScuUk5ajmW7BXtVfjHOfwTjrPIuxcXAuAY6ndKW8h46xcYBDGOthcgZlQLhvN9I4G3hQXXYtys1ICbxtnDx8pS5zYmv6XCZ5nwHwTeD8+rq8pvHnxrTzafSxp9QvJ2WQs7OBEyg9Uy5r5OGLdPR+ohyAHtCLZ4j83f/ZJvi53ko5gCflZrLjKPcC9DoLvKK1/EV13h/qPjkOWEDpqpvAp8bZ1ry6zMIBeZr0fQb1u9MrjytqGje1yulJjeUfVZdZBPykltO3GusmcOhM/xZX9deMZ2BVf00mGNT1NqMMGPZHSu+hW4DvAS/vWHZrSq+gcyndS5dSGlPPBt4EzGks+4nGQatv10RKPW+v99MrG9OnEgwWNtbt95rXWH5NSo+hM+u6i+pnu5pyBfWicbZ1Wk1v9wnkb1LBoK67EyVQ3VTL67p6kP+7jmVfRgliF1Fu8ltSP99pNG4m7LOd5REMbmBwOe3QWP7BlGrH79fv6531M/2RcqPezjP1+/M19vKxl1rl1GGdb6EMp7xd+iOQbDPQKml7So+o9xsIpMIrA0mSVwaSJIOBJAmDgSQJxyaaFhFhQ4w0zTIzBi+lYXllIEkyGEiSDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiRgjZnOgDRTMrNzekQs55xIM88rA0mSwUCSZDWRVnL9qoImso7VRloVeGUgSTIYSJKsJtJKZjLVQhNJ0yojray8MpAkGQwkSQYDSRK2GWglMB3tBMNuyzYErSy8MpAkGQwkSQYDSRIGA0kSBgNJEgYDSRJ2LZWmxKEqtLLwykCSZDCQJFlNpBXU8rzrWFoVeGUgSTIYSJIMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkYI2ZzoC0IouImc6CNBJeGUiSDAaSJKuJtIJqVs9k5gzmRFo5eGUgSTIYSJKsJpImxN5DWll5ZSBJMhhIkgwGkiRsM9BKwG6m0tR5ZSBJMhhIkqwm0kqm3fVzFNVGdifVqsArA0mSwUCSZDCQJGGbgVZyw3Y7tV1AqzqvDCRJBgNJktVEWoVYFST155WBJMlgIEkyGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJIwGEiSMBhIkjAYSJKAyMyZzoMkaYZ5ZSBJMhhIkgwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJAwGkiQMBpIkDAaSJOD/A+JHSqwy1JwdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_specific_data(args=dict(), cuda=False):\n",
    "    '''\n",
    "    use this function to get examples of data with specific class labels\n",
    "    inputs: \n",
    "        args - dictionary whose keys can include {shape, scale, orientation,\n",
    "                posX, posY} and values can include any integers less than the \n",
    "                corresponding size of that label dimension\n",
    "        cuda - bool to indicate whether the output should be placed on GPU\n",
    "    '''\n",
    "    names_dict = {'shape': 1, 'scale': 2, 'orientation': 3, 'posX': 4, 'posY': 5}\n",
    "    selected_ind = np.ones(imgs.shape[0], dtype=bool)\n",
    "    for k,v in args.items():\n",
    "        col_id = names_dict[k]\n",
    "        selected_ind = np.bitwise_and(selected_ind, labels[:, col_id] == v)\n",
    "    ind = np.random.choice(np.arange(imgs.shape[0])[selected_ind])\n",
    "    x = torch.from_numpy(imgs[ind].reshape(1,64**2).astype(np.float32))\n",
    "    y = torch.from_numpy(labels[ind].reshape(1,6).astype(np.float32))\n",
    "    if not cuda:\n",
    "        return x,y\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    return x,y\n",
    "\n",
    "def plot_image(x):\n",
    "    x = x.cpu()\n",
    "    plt.figure()\n",
    "    plt.imshow(x.reshape(64,64), interpolation='nearest', cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "\n",
    "def see_specific_image(args=dict(), verbose=True):\n",
    "    '''\n",
    "    use this function to get examples of data with specific class labels\n",
    "    inputs: \n",
    "        args - dictionary whose keys can include {shape, scale, orientation,\n",
    "                posX, posY} and values can include any integers less than the \n",
    "                corresponding size of that label dimension\n",
    "        verbose - bool to indicate whether the full class label should be written \n",
    "                    as the title of the plot\n",
    "    '''\n",
    "    x,y = get_specific_data(args, cuda=False)\n",
    "    plot_image(x)\n",
    "    if verbose:\n",
    "        string = ''\n",
    "        for i, s in enumerate(['Shape', 'Scale', 'Orientation', 'PosX', 'PosY']):\n",
    "            string += '%s: %d, ' % (s, int(y[0][i+1]))\n",
    "            if i == 2:\n",
    "                string = string[:-2] + '\\n'\n",
    "        plt.title(string[:-2])\n",
    "        \n",
    "def compare_reconstruction(original, recon):\n",
    "    \"\"\"\n",
    "    compare two images side by side\n",
    "    inputs:\n",
    "        original - array for original image\n",
    "        recon - array for recon image\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax0 = fig.add_subplot(121)\n",
    "    plt.imshow(original.cpu().reshape(64,64), cmap='Greys_r',  interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.title('original')\n",
    "    ax1 = fig.add_subplot(122)\n",
    "    plt.imshow(recon.cpu().reshape(64,64), cmap='Greys_r',  interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.title('reconstruction')\n",
    "    \n",
    "def compare_to_density(original, recons):\n",
    "    \"\"\"\n",
    "    compare two images side by side\n",
    "    inputs:\n",
    "        original - array for original image\n",
    "        recon - array of multiple recon images\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax0 = fig.add_subplot(121)\n",
    "    plt.imshow(original.cpu().reshape(64,64), cmap='Greys_r',  interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.title('original')\n",
    "    ax1 = fig.add_subplot(122)\n",
    "    plt.imshow(torch.mean(recons.cpu(), 0).reshape(64,64), cmap='Greys_r',  interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.title('reconstructions')\n",
    "\n",
    "        \n",
    "see_specific_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training or Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(svi, train_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for xs,ys in train_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            xs = xs.cuda()\n",
    "            ys = ys.cuda()\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        epoch_loss += svi.step(xs, ys)\n",
    "\n",
    "    # return epoch loss\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train\n",
    "\n",
    "def evaluate(svi, test_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    test_loss = 0.\n",
    "    # compute the loss over the entire test set\n",
    "    for xs, ys in test_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            xs = xs.cuda()\n",
    "            ys = ys.cuda()\n",
    "        # compute ELBO estimate and accumulate loss\n",
    "        test_loss += svi.evaluate_loss(xs, ys)\n",
    "    normalizer_test = len(test_loader.dataset)\n",
    "    total_epoch_loss_test = test_loss / normalizer_test\n",
    "    return total_epoch_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run options\n",
    "LEARNING_RATE = 1.0e-3\n",
    "\n",
    "# Run only for a single iteration for testing\n",
    "NUM_EPOCHS = 0\n",
    "TEST_FREQUENCY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################\n",
    "### FOR SAVING AND LOADING MODEL\n",
    "################################\n",
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "PATH = \"trained_model.save\"\n",
    "\n",
    "# new model\n",
    "# vae = CVAE(use_cuda=USE_CUDA)\n",
    "\n",
    "# save current model\n",
    "# torch.save(vae.state_dict(), PATH)\n",
    "\n",
    "# to load params from trained model\n",
    "vae = CVAE(use_cuda=USE_CUDA)\n",
    "vae.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c095b6e044043bcab32a8ffbae80d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# setup the optimizer\n",
    "adam_args = {\"lr\": LEARNING_RATE}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "test_elbo = []\n",
    "# training loop\n",
    "\n",
    "VERBOSE = True\n",
    "pbar = tqdm(range(NUM_EPOCHS))\n",
    "for epoch in pbar:\n",
    "    total_epoch_loss_train = train(svi, data_loaders[\"train\"], use_cuda=USE_CUDA)\n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "    if VERBOSE:\n",
    "        print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "    if epoch % TEST_FREQUENCY == 0:\n",
    "        # report test diagnostics\n",
    "        total_epoch_loss_test = evaluate(svi, data_loaders[\"test\"], use_cuda=USE_CUDA)\n",
    "        test_elbo.append(-total_epoch_loss_test)\n",
    "        if VERBOSE:\n",
    "            print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the reconstruction accuracy of trained VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5257288cb84a9daa66378b60010af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='data id', max=256), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f(i)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = iter(data_loaders[\"train\"])\n",
    "xs, ys = next(data_iter)\n",
    "if USE_CUDA:\n",
    "    xs = xs.cuda()\n",
    "    ys = ys.cuda()\n",
    "rs = vae.reconstruct_image(xs, ys)\n",
    "\n",
    "def f(i):\n",
    "    compare_reconstruction(xs[i], rs[i])\n",
    "    \n",
    "interact(f, i=widgets.IntSlider(min=0, max=xs.shape[0], step=1, value=0,description='data id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Structural Causal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   4,  10,  50,  82, 114])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dims = vae.label_shape\n",
    "label_dim_offsets = np.cumsum(label_dims)\n",
    "label_dim_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCM():\n",
    "    def __init__(self, vae, mu, sigma):\n",
    "        self.vae = vae\n",
    "        self.image_dim = vae.image_dim\n",
    "        self.z_dim = vae.z_dim\n",
    "        \n",
    "        # these are used for f_X\n",
    "        self.label_dims = vae.label_shape\n",
    "        \n",
    "        def f_X(Y, Z, N):\n",
    "            zs = Z.cuda()\n",
    "            \n",
    "            # convert the labels to one hot\n",
    "            ys = [torch.tensor([0])]\n",
    "            ys.append(torch.nn.functional.one_hot(torch.tensor(Y[0]), int(self.label_dims[1])))\n",
    "            ys.append(torch.nn.functional.one_hot(torch.tensor(Y[1]), int(self.label_dims[2])))\n",
    "            ys.append(torch.nn.functional.one_hot(torch.tensor(Y[2]), int(self.label_dims[3])))\n",
    "            ys.append(torch.nn.functional.one_hot(torch.tensor(Y[3]), int(self.label_dims[4])))\n",
    "            ys.append(torch.nn.functional.one_hot(torch.tensor(Y[4]), int(self.label_dims[5])))\n",
    "            ys = torch.cat(ys).to(torch.float32).reshape(1,-1).cuda()\n",
    "            \n",
    "            p = vae.decoder.forward(zs, ys)\n",
    "            return (N < p.cpu()).type(torch.float)\n",
    "        \n",
    "        def f_Y(N):\n",
    "            m = torch.distributions.gumbel.Gumbel(torch.zeros(N.size(0)), torch.ones(N.size(0)))\n",
    "            return torch.argmax(torch.add(torch.log(N), m.sample())).item()\n",
    "        \n",
    "        def f_Z(N):\n",
    "            return N * sigma + mu\n",
    "        \n",
    "        def model(noise): \n",
    "            N_X = pyro.sample( 'N_X', noise['N_X'].to_event(1) )\n",
    "            # denoted using the index in the sequence \n",
    "            # that they are stored in as vae.label_names:\n",
    "            # ['shape', 'scale', 'orientation', 'posX', 'posY']\n",
    "            N_Y_1 = pyro.sample( 'N_Y_1', noise['N_Y_1'].to_event(1) )\n",
    "            N_Y_2 = pyro.sample( 'N_Y_2', noise['N_Y_2'].to_event(1) )\n",
    "            N_Y_3 = pyro.sample( 'N_Y_3', noise['N_Y_3'].to_event(1) )\n",
    "            N_Y_4 = pyro.sample( 'N_Y_4', noise['N_Y_4'].to_event(1) )\n",
    "            N_Y_5 = pyro.sample( 'N_Y_5', noise['N_Y_5'].to_event(1) )\n",
    "            N_Z = pyro.sample( 'N_Z', noise['N_Z'].to_event(1) )\n",
    "\n",
    "            Z = pyro.sample('Z', dist.Normal( f_Z( N_Z ), 1e-1).to_event(1) )\n",
    "            Y_1_mu = f_Y(N_Y_1)\n",
    "            Y_2_mu = f_Y(N_Y_2)\n",
    "            Y_3_mu = f_Y(N_Y_3)\n",
    "            Y_4_mu = f_Y(N_Y_4)\n",
    "            Y_5_mu = f_Y(N_Y_5)\n",
    "            Y_1 = pyro.sample('Y_1', dist.Normal( Y_1_mu, 1e-1) )\n",
    "            Y_2 = pyro.sample('Y_2', dist.Normal( Y_2_mu, 1e-1) )\n",
    "            Y_3 = pyro.sample('Y_3', dist.Normal( Y_3_mu, 1e-1) )\n",
    "            Y_4 = pyro.sample('Y_4', dist.Normal( Y_4_mu, 1e-1) )\n",
    "            Y_5 = pyro.sample('Y_5', dist.Normal( Y_5_mu, 1e-1) )\n",
    "            Y_mu = (Y_1_mu, Y_2_mu, Y_3_mu, Y_4_mu, Y_5_mu)\n",
    "            X = pyro.sample('X', dist.Normal( f_X( Y_mu, Z, N_X ), 1e-1).to_event(1))\n",
    "\n",
    "            noise_samples = N_X, (N_Y_1, N_Y_2, N_Y_3, N_Y_4, N_Y_5), N_Z\n",
    "            variable_samples = X, (Y_1, Y_2, Y_3, Y_4, Y_5), Z\n",
    "\n",
    "            return variable_samples, noise_samples\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        self.init_noise = {\n",
    "            'N_X'   : dist.Uniform(torch.zeros(vae.image_dim), torch.ones(vae.image_dim)),\n",
    "            'N_Z'   : dist.Normal(torch.zeros(vae.z_dim), torch.ones(vae.z_dim)),\n",
    "            'N_Y_1' : dist.Uniform(torch.zeros(label_dims[1]),torch.ones(self.label_dims[1])),\n",
    "            'N_Y_2' : dist.Uniform(torch.zeros(label_dims[2]),torch.ones(self.label_dims[2])),\n",
    "            'N_Y_3' : dist.Uniform(torch.zeros(label_dims[3]),torch.ones(self.label_dims[3])),\n",
    "            'N_Y_4' : dist.Uniform(torch.zeros(label_dims[4]),torch.ones(self.label_dims[4])),\n",
    "            'N_Y_5' : dist.Uniform(torch.zeros(label_dims[5]),torch.ones(self.label_dims[5]))            \n",
    "        }\n",
    "        \n",
    "        \n",
    "        \n",
    "    def update_noise_svi(self, obs_data):\n",
    "        # assume all noise variables are normal distributions\n",
    "        # use svi to find out the mu, sigma of the distributions\n",
    "        # for the condition outlined in obs_data\n",
    "        \n",
    "        def guide(noise):\n",
    "            # create params with constraints\n",
    "            mu = {'N_X': pyro.param('N_X_mu', 0.5*torch.ones(self.image_dim),\n",
    "                                    constraint = constraints.interval(0., 1.)),\n",
    "                  'N_Z': pyro.param('N_Z_mu', torch.zeros(self.z_dim),\n",
    "                                    constraint = constraints.interval(-3., 3.)),\n",
    "                  'N_Y_1': pyro.param('N_Y_1_mu', 0.5*torch.ones(self.label_dims[1]),\n",
    "                                    constraint = constraints.interval(0., 1.)),\n",
    "                  'N_Y_2': pyro.param('N_Y_2_mu', 0.5*torch.ones(self.label_dims[2]),\n",
    "                                    constraint = constraints.interval(0., 1.)),\n",
    "                  'N_Y_3': pyro.param('N_Y_3_mu', 0.5*torch.ones(self.label_dims[3]),\n",
    "                                    constraint = constraints.interval(0., 1.)),\n",
    "                  'N_Y_4': pyro.param('N_Y_4_mu', 0.5*torch.ones(self.label_dims[4]),\n",
    "                                    constraint = constraints.interval(0., 1.)),\n",
    "                  'N_Y_5': pyro.param('N_Y_5_mu', 0.5*torch.ones(self.label_dims[5]),\n",
    "                                    constraint = constraints.interval(0., 1.))\n",
    "                }\n",
    "            sigma = {'N_X': pyro.param('N_X_sigma', 0.1*torch.ones(self.image_dim),\n",
    "                                    constraint = constraints.interval(0.0001, 0.5)),\n",
    "                      'N_Z': pyro.param('N_Z_sigma', torch.ones(self.z_dim),\n",
    "                                        constraint = constraints.interval(0.0001, 3.)),\n",
    "                      'N_Y_1': pyro.param('N_Y_1_sigma', 0.1*torch.ones(self.label_dims[1]),\n",
    "                                        constraint = constraints.interval(0.0001, 0.5)),\n",
    "                      'N_Y_2': pyro.param('N_Y_2_sigma', 0.1*torch.ones(self.label_dims[2]),\n",
    "                                        constraint = constraints.interval(0.0001, 0.5)),\n",
    "                      'N_Y_3': pyro.param('N_Y_3_sigma', 0.1*torch.ones(self.label_dims[3]),\n",
    "                                        constraint = constraints.interval(0.0001, 0.5)),\n",
    "                      'N_Y_4': pyro.param('N_Y_4_sigma', 0.1*torch.ones(self.label_dims[4]),\n",
    "                                        constraint = constraints.interval(0.0001, 0.5)),\n",
    "                      'N_Y_5': pyro.param('N_Y_5_sigma', 0.1*torch.ones(self.label_dims[5]),\n",
    "                                    constraint = constraints.interval(0.0001, 0.5))\n",
    "                }\n",
    "            for noise_term in noise.keys():\n",
    "                pyro.sample(noise_term, dist.Normal(mu[noise_term], sigma[noise_term]).to_event(1))\n",
    "        \n",
    "                \n",
    "        \n",
    "        obs_model = pyro.condition(self.model, obs_data)\n",
    "\n",
    "        pyro.clear_param_store()\n",
    "        svi = SVI(\n",
    "            model= obs_model,\n",
    "            guide= guide,\n",
    "            optim= SGD({\"lr\": 1e-3, 'momentum': 0.1}),\n",
    "            loss=Trace_ELBO(retain_graph=True)\n",
    "        )\n",
    "        \n",
    "        num_steps = 1000\n",
    "        samples = defaultdict(list)\n",
    "        for t in range(num_steps):\n",
    "            loss = svi.step(self.init_noise)\n",
    "            if t % 100 == 0:\n",
    "                print(\"step %d: loss of %.2f\" % (t, loss))\n",
    "            for noise in self.init_noise.keys():\n",
    "                mu = '{}_mu'.format(noise)\n",
    "                sigma = '{}_sigma'.format(noise)\n",
    "                samples[mu].append(pyro.param(mu).detach().numpy())\n",
    "                samples[sigma].append(pyro.param(sigma).detach().numpy())\n",
    "        means = {k: torch.tensor(np.array(v).mean(axis=0)) for k, v in samples.items()}\n",
    "        \n",
    "        updated_noise = {\n",
    "            'N_X'  : dist.Normal(means['N_X_mu'], means['N_X_sigma']),\n",
    "            'N_Z'  : dist.Normal(means['N_Z_mu'], means['N_Z_sigma']),\n",
    "            'N_Y_1': dist.Normal(means['N_Y_1_mu'], means['N_Y_1_sigma']),\n",
    "            'N_Y_2': dist.Normal(means['N_Y_2_mu'], means['N_Y_2_sigma']),\n",
    "            'N_Y_3': dist.Normal(means['N_Y_3_mu'], means['N_Y_3_sigma']),\n",
    "            'N_Y_4': dist.Normal(means['N_Y_4_mu'], means['N_Y_4_sigma']),\n",
    "            'N_Y_5': dist.Normal(means['N_Y_5_mu'], means['N_Y_5_sigma']),\n",
    "        }\n",
    "        \n",
    "        return updated_noise\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.model(self.init_noise)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  2.,  3.,  2.,  8., 21.]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ0AAAENCAYAAAAVEjAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAA9xJREFUeJzt3MFuwjAUAMG44v9/2b0iBFUWQXHIzLGiUk6r9+zAmHNuAHv9fPoBgGMRDSARDSARDSARDSARDSARDSARDSARDSARDSARDSARDSC5fPoBnjHG8C07eLM557j3d5MGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkIgGkFw+/QCsYc6563NjjDc/CaszaQCJaACJ9eTE9q4ke//H6nIOJg0gEQ0gEQ0gcaZxIs+cYcAtkwaQiAaQWE8W9op14j+vQW+f1xXsdzJpAIloAIn1ZCHvuN1wY8KrmTSARDSARDSARDSARDSARDSAxJUrL+MN0HMwaQCJaACJaACJaACJaACJaACJaACJaACJaACJN0IXcvtG5RF+QMdboOdj0gAS0QAS0QASZxoLuz4vOML5Budg0gAS0QAS68lBrHId64oVkwaQiAaQiAaQONM4qL/OFlzP8k4mDSARDSCxnnyhR6vLs2uLa1aumTSARDSAxHpyIm5ceAWTBpCIBpCIBpA402DbtnW+Rcv6TBpAIhpAYj3hLm+B8ohJA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0hEA0jGnPPTzwAciEkDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSEQDSH4BSpg5NAzYUfEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing scm works\n",
    "ox, y = get_specific_data(cuda=True)\n",
    "mu, sigma = vae.encoder.forward(ox,vae.remap_y(y))\n",
    "scm = SCM(vae, mu.cpu(), sigma.cpu())\n",
    "print(y)\n",
    "plot_image(ox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss of 29364.76\n",
      "step 100: loss of 8383.37\n",
      "step 200: loss of 70139.06\n",
      "step 300: loss of 37501.85\n",
      "step 400: loss of inf\n",
      "step 500: loss of 85976.29\n",
      "step 600: loss of inf\n",
      "step 700: loss of inf\n",
      "step 800: loss of inf\n",
      "step 900: loss of inf\n",
      "{'N_X': Normal(loc: torch.Size([4096]), scale: torch.Size([4096])), 'N_Z': Normal(loc: torch.Size([50]), scale: torch.Size([50])), 'N_Y_1': Normal(loc: torch.Size([3]), scale: torch.Size([3])), 'N_Y_2': Normal(loc: torch.Size([6]), scale: torch.Size([6])), 'N_Y_3': Normal(loc: torch.Size([40]), scale: torch.Size([40])), 'N_Y_4': Normal(loc: torch.Size([32]), scale: torch.Size([32])), 'N_Y_5': Normal(loc: torch.Size([32]), scale: torch.Size([32]))}\n"
     ]
    }
   ],
   "source": [
    "cond_data = {}\n",
    "for i in range(1, 6):\n",
    "    cond_data[\"Y_{}\".format(i)] = torch.tensor(y[0,i].cpu()).to(torch.float32)\n",
    "\n",
    "cond_noise = scm.update_noise_svi(cond_data)\n",
    "\n",
    "print(cond_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(rx,_,_), _ = scm.model(cond_noise)\n",
    "compare_reconstruction(ox, rx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check that do-operation should work on trained network\n",
    "\n",
    "At one point I was concerned that the network was encoding too much information in the latent encoding z and thus conditioning on the labels wasnt enough to change the output.  According to the results below, that is not the case.  We should be able to condition on the labels and get sensible outputs from the conditioned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top:  tensor([[ 0.,  2.,  3.,  3., 29., 16.]], device='cuda:0')\n",
      "bottom:  tensor([[ 0.,  1.,  3.,  3., 29., 16.]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "original, y_original = get_specific_data(cuda=True)\n",
    "print('top: ',y_original)\n",
    "mu, sigma = vae.encoder.forward(original,vae.remap_y(y_original))\n",
    "B = 100\n",
    "zs = torch.cat([dist.Normal(mu.cpu(), sigma.cpu()).sample() for a in range(B)], 0)\n",
    "ys = torch.cat([vae.remap_y(y_original) for a in range(B)], 0)\n",
    "rs = vae.decoder.forward(zs.cuda(), ys).detach()\n",
    "compare_to_density(original,rs)\n",
    "\n",
    "y_new = torch.tensor(y_original)\n",
    "y_new[0,1] = (y_original[0,1] + 1) % 2\n",
    "print('bottom: ', y_new)\n",
    "zs = torch.cat([dist.Normal(mu.cpu(), sigma.cpu()).sample() for a in range(B)], 0)\n",
    "ys = torch.cat([vae.remap_y(y_new) for a in range(B)], 0)\n",
    "rs = vae.decoder.forward(zs.cuda(), ys).detach()\n",
    "compare_to_density(original,rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

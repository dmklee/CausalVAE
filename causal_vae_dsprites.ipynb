{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pyro\n",
    "from pyro.contrib.examples.util import print_and_log\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
    "from pyro.optim import Adam\n",
    "\n",
    "# Change figure aesthetics\n",
    "%matplotlib inline\n",
    "sns.set_context('talk', font_scale=1.2, rc={'lines.linewidth': 1.5})\n",
    "\n",
    "USE_CUDA = True\n",
    "\n",
    "pyro.enable_validation(True)\n",
    "pyro.distributions.enable_validation(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, image_dim, label_dim, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.image_dim = image_dim\n",
    "        self.label_dim = label_dim\n",
    "        self.z_dim = z_dim\n",
    "        # setup the three linear transformations used\n",
    "        self.fc1 = nn.Linear(self.image_dim+self.label_dim, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.fc31 = nn.Linear(1000, z_dim)  # mu values\n",
    "        self.fc32 = nn.Linear(1000, z_dim)  # sigma values\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, xs, ys):\n",
    "        # define the forward computation on the image xs and label ys\n",
    "        # first shape the mini-batch to have pixels in the rightmost dimension\n",
    "        xs = xs.reshape(-1, self.image_dim)\n",
    "        #now concatenate the image and label\n",
    "        inputs = torch.cat((xs,ys), -1)\n",
    "        # then compute the hidden units\n",
    "        hidden1 = self.softplus(self.fc1(inputs))\n",
    "        hidden2 = self.softplus(self.fc2(hidden1))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc31(hidden2)\n",
    "        z_scale = torch.exp(self.fc32(hidden2))\n",
    "        return z_loc, z_scale\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, image_dim, label_dim, z_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        # setup the two linear transformations used\n",
    "        hidden_dim = 1000\n",
    "        self.fc1 = nn.Linear(z_dim+label_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, image_dim)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, zs, ys):\n",
    "        # define the forward computation on the latent z and label y\n",
    "        # first concatenate z and y\n",
    "        inputs = torch.cat((zs, ys),-1)\n",
    "        # then compute the hidden units\n",
    "        hidden1 = self.softplus(self.fc1(inputs))\n",
    "        hidden2 = self.softplus(self.fc2(hidden1))\n",
    "        hidden3 = self.softplus(self.fc3(hidden2))\n",
    "        # return the parameter for the output Bernoulli\n",
    "        # each is of size batch_size x 784\n",
    "        loc_img = self.sigmoid(self.fc4(hidden3))\n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, config_enum=None, use_cuda=False, aux_loss_multiplier=None):\n",
    "\n",
    "        super(CVAE, self).__init__()\n",
    "    \n",
    "        self.image_dim = 64**2\n",
    "        self.label_shape = np.array((1,3,6,40,32,32))\n",
    "        self.label_names = np.array(('color', 'shape', 'scale', 'orientation', 'posX', 'posY'))\n",
    "        self.label_dim = np.sum(self.label_shape)\n",
    "        self.z_dim = 50                                    \n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        # define and instantiate the neural networks representing\n",
    "        # the paramters of various distributions in the model\n",
    "        self.setup_networks()\n",
    "\n",
    "    def setup_networks(self):\n",
    "        self.encoder = Encoder(self.image_dim, self.label_dim, self.z_dim)\n",
    "\n",
    "        self.decoder = Decoder(self.image_dim, self.label_dim, self.z_dim)\n",
    "\n",
    "        # using GPUs for faster training of the networks\n",
    "        if self.use_cuda:\n",
    "            self.cuda()\n",
    "\n",
    "    def model(self, xs, ys):\n",
    "        \"\"\"\n",
    "        The model corresponds to the following generative process:\n",
    "        p(z) = normal(0,I)              # dsprites label (latent)\n",
    "        p(x|y,z) = bernoulli(loc(y,z))   # an image\n",
    "        loc is given by a neural network  `decoder`\n",
    "\n",
    "        :param xs: a batch of scaled vectors of pixels from an image\n",
    "        :param ys: a batch of the class labels i.e.\n",
    "                   the digit corresponding to the image(s)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # register this pytorch module and all of its sub-modules with pyro\n",
    "        pyro.module(\"cvae\", self)\n",
    "\n",
    "        batch_size = xs.size(0)\n",
    "        options = dict(dtype=xs.dtype, device=xs.device)\n",
    "        with pyro.plate(\"data\"):\n",
    "\n",
    "            prior_loc = torch.zeros(batch_size, self.z_dim, **options)\n",
    "            prior_scale = torch.ones(batch_size, self.z_dim, **options)\n",
    "            zs = pyro.sample(\"z\", dist.Normal(prior_loc, prior_scale).to_event(1))\n",
    "            \n",
    "            # if the label y (which digit to write) is supervised, sample from the\n",
    "            # constant prior, otherwise, observe the value (i.e. score it against the constant prior)\n",
    "    \n",
    "            loc = self.decoder.forward(zs, self.remap_y(ys))\n",
    "            pyro.sample(\"x\", dist.Bernoulli(loc).to_event(1), obs=xs)\n",
    "            # return the loc so we can visualize it later\n",
    "            return loc\n",
    "\n",
    "    def guide(self, xs, ys):\n",
    "        \"\"\"\n",
    "        The guide corresponds to the following:\n",
    "        q(z|x,y) = normal(loc(x,y),scale(x,y))       # infer latent class from an image and the label \n",
    "        loc, scale are given by a neural network `encoder`\n",
    "\n",
    "        :param xs: a batch of scaled vectors of pixels from an image\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # inform Pyro that the variables in the batch of xs are conditionally independent\n",
    "        with pyro.plate(\"data\"):\n",
    "            # sample (and score) the latent handwriting-style with the variational\n",
    "            # distribution q(z|x) = normal(loc(x),scale(x))\n",
    "    \n",
    "            loc, scale = self.encoder.forward(xs, self.remap_y(ys))\n",
    "            pyro.sample(\"z\", dist.Normal(loc, scale).to_event(1))\n",
    "            \n",
    "    def remap_y(self, ys):\n",
    "        new_ys = []\n",
    "        options = dict(dtype=ys.dtype, device=ys.device)\n",
    "        for i, label_length in enumerate(self.label_shape):\n",
    "            prior = torch.ones(ys.size(0), label_length, **options) / (1.0 * label_length)\n",
    "            new_ys.append(pyro.sample(\"y_%s\" % self.label_names[i], dist.OneHotCategorical(prior), \n",
    "                                   obs=torch.nn.functional.one_hot(ys[:,i].to(torch.int64), int(label_length))))\n",
    "        new_ys = torch.cat(new_ys, -1)\n",
    "        return new_ys.to(torch.float32)\n",
    "            \n",
    "    def reconstruct_image(self, xs, ys):\n",
    "        # backward\n",
    "        sim_z_loc, sim_z_scale = self.encoder.forward(xs, self.remap_y(ys))\n",
    "        zs = dist.Normal(sim_z_loc, sim_z_scale).to_event(1).sample()\n",
    "        # forward\n",
    "        loc = self.decoder.forward(zs, self.remap_y(ys))\n",
    "        return dist.Bernoulli(loc).to_event(1).sample()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data_loaders(train_x, test_x, train_y, test_y, batch_size=128, use_cuda=False):\n",
    "    train_dset = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(train_x.astype(np.float32)).reshape(-1, 4096),\n",
    "        torch.from_numpy(train_y.astype(np.float32))\n",
    "    )\n",
    "    \n",
    "    test_dset = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(test_x.astype(np.float32)).reshape(-1, 4096),\n",
    "        torch.from_numpy(test_y.astype(np.float32))\n",
    "    )    \n",
    "    kwargs = {'num_workers': 1, 'pin_memory': use_cuda}\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dset, batch_size=batch_size, shuffle=False, **kwargs\n",
    "    )\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dset, batch_size=batch_size, shuffle=False, **kwargs\n",
    "    )\n",
    "    \n",
    "    return {\"train\":train_loader, \"test\":test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_zip = np.load(\n",
    "    'dsprites-dataset/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz',\n",
    "    encoding = 'bytes',\n",
    "    allow_pickle=True\n",
    ")\n",
    "imgs = dataset_zip['imgs']\n",
    "labels = dataset_zip['latents_classes']\n",
    "label_sizes = dataset_zip['metadata'][()][b'latents_sizes']\n",
    "label_names = dataset_zip['metadata'][()][b'latents_names']\n",
    "\n",
    "# Sample imgs randomly\n",
    "indices_sampled = np.arange(imgs.shape[0])\n",
    "np.random.shuffle(indices_sampled)\n",
    "imgs_sampled = imgs[indices_sampled]\n",
    "labels_sampled = labels[indices_sampled]\n",
    "\n",
    "data_loaders = setup_data_loaders(\n",
    "    imgs_sampled[1000:],\n",
    "    imgs_sampled[:1000],\n",
    "    labels_sampled[1000:],\n",
    "    labels_sampled[:1000],\n",
    "    batch_size=256,\n",
    "    use_cuda=USE_CUDA\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ae45f1988e46e19ccc4b27f64dc946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='shape', max=2), IntSlider(value=4, description='scale', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.find_in_dataset(shape, scale, orient, posX, posY)>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_names = ['shape', 'scale', 'orientation', 'posX', 'posY']\n",
    "y_shapes = np.array((3,6,40,32,32))\n",
    "img_dict = {}\n",
    "for i, img in enumerate(imgs_sampled):\n",
    "    img_dict[tuple(labels_sampled[i])] = img\n",
    "    \n",
    "def find_in_dataset(shape, scale, orient, posX, posY):\n",
    "    fig = plt.figure()\n",
    "    img = img_dict[(0, shape, scale, orient, posX, posY)]\n",
    "    plt.imshow(img.reshape(64,64), cmap='Greys_r',  interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    \n",
    "interact(find_in_dataset, shape=widgets.IntSlider(min=0, max=2, step=1, value=npr.randint(2)),\n",
    "                          scale=widgets.IntSlider(min=0, max=5, step=1, value=npr.randint(5)),\n",
    "                            orient=widgets.IntSlider(min=0, max=39, step=1, value=npr.randint(39)),\n",
    "                            posX=widgets.IntSlider(min=0, max=31, step=1, value=npr.randint(31)),\n",
    "                            posY=widgets.IntSlider(min=0, max=31, step=1, value=npr.randint(31)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_specific_data(args=dict(), cuda=False):\n",
    "    '''\n",
    "    use this function to get examples of data with specific class labels\n",
    "    inputs: \n",
    "        args - dictionary whose keys can include {shape, scale, orientation,\n",
    "                posX, posY} and values can include any integers less than the \n",
    "                corresponding size of that label dimension\n",
    "        cuda - bool to indicate whether the output should be placed on GPU\n",
    "    '''\n",
    "    names_dict = {'shape': 1, 'scale': 2, 'orientation': 3, 'posX': 4, 'posY': 5}\n",
    "    selected_ind = np.ones(imgs.shape[0], dtype=bool)\n",
    "    for k,v in args.items():\n",
    "        col_id = names_dict[k]\n",
    "        selected_ind = np.bitwise_and(selected_ind, labels[:, col_id] == v)\n",
    "    ind = np.random.choice(np.arange(imgs.shape[0])[selected_ind])\n",
    "    x = torch.from_numpy(imgs[ind].reshape(1,64**2).astype(np.float32))\n",
    "    y = torch.from_numpy(labels[ind].reshape(1,6).astype(np.float32))\n",
    "    if not cuda:\n",
    "        return x,y\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    return x,y\n",
    "\n",
    "def plot_image(x):\n",
    "    x = x.cpu()\n",
    "    plt.figure()\n",
    "    plt.imshow(x.reshape(64,64), interpolation='nearest', cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "\n",
    "def see_specific_image(args=dict(), verbose=True):\n",
    "    '''\n",
    "    use this function to get examples of data with specific class labels\n",
    "    inputs: \n",
    "        args - dictionary whose keys can include {shape, scale, orientation,\n",
    "                posX, posY} and values can include any integers less than the \n",
    "                corresponding size of that label dimension\n",
    "        verbose - bool to indicate whether the full class label should be written \n",
    "                    as the title of the plot\n",
    "    '''\n",
    "    x,y = get_specific_data(args, cuda=False)\n",
    "    plot_image(x)\n",
    "    if verbose:\n",
    "        string = ''\n",
    "        for i, s in enumerate(['Shape', 'Scale', 'Orientation', 'PosX', 'PosY']):\n",
    "            string += '%s: %d, ' % (s, int(y[0][i+1]))\n",
    "            if i == 2:\n",
    "                string = string[:-2] + '\\n'\n",
    "        plt.title(string[:-2])\n",
    "        \n",
    "def compare_reconstruction(original, recon):\n",
    "    \"\"\"\n",
    "    compare two images side by side\n",
    "    inputs:\n",
    "        original - array for original image\n",
    "        recon - array for recon image\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax0 = fig.add_subplot(121)\n",
    "    plt.imshow(original.cpu().reshape(64,64), cmap='Greys_r',  interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.title('original')\n",
    "    ax1 = fig.add_subplot(122)\n",
    "    plt.imshow(recon.cpu().reshape(64,64), cmap='Greys_r',  interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.title('reconstruction')\n",
    "    \n",
    "def compare_to_density(original, recons):\n",
    "    \"\"\"\n",
    "    compare two images side by side\n",
    "    inputs:\n",
    "        original - array for original image\n",
    "        recon - array of multiple recon images\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax0 = fig.add_subplot(121)\n",
    "    plt.imshow(original.cpu().reshape(64,64), cmap='Greys_r',  interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.title('original')\n",
    "    ax1 = fig.add_subplot(122)\n",
    "    plt.imshow(torch.mean(recons.cpu(), 0).reshape(64,64), cmap='Greys_r',  interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.title('reconstructions')\n",
    "\n",
    "        \n",
    "see_specific_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training or Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(svi, train_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for xs,ys in train_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            xs = xs.cuda()\n",
    "            ys = ys.cuda()\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        epoch_loss += svi.step(xs, ys)\n",
    "\n",
    "    # return epoch loss\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train\n",
    "\n",
    "def evaluate(svi, test_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    test_loss = 0.\n",
    "    # compute the loss over the entire test set\n",
    "    for xs, ys in test_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            xs = xs.cuda()\n",
    "            ys = ys.cuda()\n",
    "        # compute ELBO estimate and accumulate loss\n",
    "        test_loss += svi.evaluate_loss(xs, ys)\n",
    "    normalizer_test = len(test_loader.dataset)\n",
    "    total_epoch_loss_test = test_loss / normalizer_test\n",
    "    return total_epoch_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run options\n",
    "LEARNING_RATE = 1.0e-3\n",
    "\n",
    "# Run only for a single iteration for testing\n",
    "NUM_EPOCHS = 0\n",
    "TEST_FREQUENCY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################\n",
    "### FOR SAVING AND LOADING MODEL\n",
    "################################\n",
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "PATH = \"trained_model.save\"\n",
    "\n",
    "# new model\n",
    "# vae = CVAE(use_cuda=USE_CUDA)\n",
    "\n",
    "# save current model\n",
    "# torch.save(vae.state_dict(), PATH)\n",
    "\n",
    "# to load params from trained model\n",
    "vae = CVAE(use_cuda=USE_CUDA)\n",
    "vae.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935fefbb79a14937bf871bd1a5a0bd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# setup the optimizer\n",
    "adam_args = {\"lr\": LEARNING_RATE}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "test_elbo = []\n",
    "# training loop\n",
    "\n",
    "VERBOSE = True\n",
    "pbar = tqdm(range(NUM_EPOCHS))\n",
    "for epoch in pbar:\n",
    "    total_epoch_loss_train = train(svi, data_loaders[\"train\"], use_cuda=USE_CUDA)\n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "    if VERBOSE:\n",
    "        print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "    if epoch % TEST_FREQUENCY == 0:\n",
    "        # report test diagnostics\n",
    "        total_epoch_loss_test = evaluate(svi, data_loaders[\"test\"], use_cuda=USE_CUDA)\n",
    "        test_elbo.append(-total_epoch_loss_test)\n",
    "        if VERBOSE:\n",
    "            print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the reconstruction accuracy of trained VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c71e47ca164895b547e33f005f85e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='data id', max=256), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f(i)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = iter(data_loaders[\"train\"])\n",
    "xs, ys = next(data_iter)\n",
    "if USE_CUDA:\n",
    "    xs = xs.cuda()\n",
    "    ys = ys.cuda()\n",
    "rs = vae.reconstruct_image(xs, ys)\n",
    "\n",
    "def f(i):\n",
    "    compare_reconstruction(xs[i], rs[i])\n",
    "    \n",
    "interact(f, i=widgets.IntSlider(min=0, max=xs.shape[0], step=1, value=0,description='data id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Structural Causal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   4,  10,  50,  82, 114])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dims = vae.label_shape\n",
    "label_dim_offsets = np.cumsum(label_dims)\n",
    "label_dim_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCM():\n",
    "    def __init__(self, vae, mu, sigma):\n",
    "        self.vae = vae\n",
    "        \n",
    "        mu = mu.cpu()\n",
    "        sigma = sigma.cpu()\n",
    "        \n",
    "        # these are used for f_X\n",
    "        label_dims = vae.label_shape\n",
    "        label_dim_offsets = np.cumsum(label_dims)\n",
    "        \n",
    "        def f_X(Y, Z, N):\n",
    "            zs = Z.cuda()\n",
    "            \n",
    "            # convert the labels to one hot\n",
    "            ys = [torch.tensor([0])]\n",
    "            ys.append(torch.nn.functional.one_hot(torch.tensor(Y[0]), int(label_dims[1])))\n",
    "            ys.append(torch.nn.functional.one_hot(torch.tensor(Y[1]), int(label_dims[2])))\n",
    "            ys.append(torch.nn.functional.one_hot(torch.tensor(Y[2]), int(label_dims[3])))\n",
    "            ys.append(torch.nn.functional.one_hot(torch.tensor(Y[3]), int(label_dims[4])))\n",
    "            ys.append(torch.nn.functional.one_hot(torch.tensor(Y[4]), int(label_dims[5])))\n",
    "            ys = torch.cat(ys).to(torch.float32).reshape(1,-1).cuda()\n",
    "            \n",
    "            p = vae.decoder.forward(zs, ys)\n",
    "            return (N < p.cpu()).type(torch.float)\n",
    "        \n",
    "        def f_Y(N):\n",
    "            return torch.argmax(N).item()\n",
    "        \n",
    "        def f_Z(N):\n",
    "            return N * sigma + mu\n",
    "        \n",
    "        def model(noise):\n",
    "            N_X = pyro.sample( 'N_X', noise['N_X'] )\n",
    "            # There are 5 Y variables and they will be\n",
    "            # denoted using the index in the sequence \n",
    "            # that they are stored in as vae.label_names:\n",
    "            # ['shape', 'scale', 'orientation', 'posX', 'posY']\n",
    "            N_Y_1 = pyro.sample( 'N_Y_1', noise['N_Y_1'] )\n",
    "            N_Y_2 = pyro.sample( 'N_Y_2', noise['N_Y_2'] )\n",
    "            N_Y_3 = pyro.sample( 'N_Y_3', noise['N_Y_3'] )\n",
    "            N_Y_4 = pyro.sample( 'N_Y_4', noise['N_Y_4'] )\n",
    "            N_Y_5 = pyro.sample( 'N_Y_5', noise['N_Y_5'] ) \n",
    "            N_Z = pyro.sample( 'N_Z', noise['N_Z'] )\n",
    "             \n",
    "            Z = pyro.sample('Z', dist.Normal( f_Z( N_Z ), 1e-1) )\n",
    "            Y_1_mu = f_Y(N_Y_1)\n",
    "            Y_2_mu = f_Y(N_Y_2)\n",
    "            Y_3_mu = f_Y(N_Y_3)\n",
    "            Y_4_mu = f_Y(N_Y_4)\n",
    "            Y_5_mu = f_Y(N_Y_5)\n",
    "            Y_1 = pyro.sample('Y_1', dist.Normal( Y_1_mu, 1e-1) )\n",
    "            Y_2 = pyro.sample('Y_2', dist.Normal( Y_2_mu, 1e-1) )\n",
    "            Y_3 = pyro.sample('Y_3', dist.Normal( Y_3_mu, 1e-1) )\n",
    "            Y_4 = pyro.sample('Y_4', dist.Normal( Y_4_mu, 1e-1) )\n",
    "            Y_5 = pyro.sample('Y_5', dist.Normal( Y_5_mu, 1e-1) )\n",
    "            Y_mu = (Y_1_mu, Y_2_mu, Y_3_mu, Y_4_mu, Y_5_mu)\n",
    "            X = pyro.sample('X', dist.Normal( f_X( Y_mu, Z, N_X ), 1e-1) )\n",
    "            \n",
    "            noise_samples = N_X, (N_Y_1, N_Y_2, N_Y_3, N_Y_4, N_Y_5), N_Z\n",
    "            variable_samples = X, (Y_1, Y_2, Y_3, Y_4, Y_5), Z\n",
    "            \n",
    "            return variable_samples, noise_samples\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        self.noise = {\n",
    "            'N_X'   : dist.Uniform(torch.zeros(vae.image_dim), torch.ones(vae.image_dim)),\n",
    "            'N_Z'   : dist.Normal(torch.zeros(vae.z_dim), torch.ones(vae.z_dim)),\n",
    "            'N_Y_1' : dist.Uniform(torch.zeros(label_dims[1]),torch.ones(label_dims[1])),\n",
    "            'N_Y_2' : dist.Uniform(torch.zeros(label_dims[2]),torch.ones(label_dims[2])),\n",
    "            'N_Y_3' : dist.Uniform(torch.zeros(label_dims[3]),torch.ones(label_dims[3])),\n",
    "            'N_Y_4' : dist.Uniform(torch.zeros(label_dims[4]),torch.ones(label_dims[4])),\n",
    "            'N_Y_5' : dist.Uniform(torch.zeros(label_dims[5]),torch.ones(label_dims[5]))            \n",
    "        }\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.model(self.noise)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just testing that it all runs\n",
    "\n",
    "x,y = get_specific_data(cuda=True)\n",
    "\n",
    "mu, sigma = vae.encoder.forward(x,vae.remap_y(y))\n",
    "scm = SCM(vae, mu, sigma)\n",
    "\n",
    "(X,Y,Z), _  = scm()\n",
    "plot_image(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCM(vae, xs):\n",
    "    z_dim = vae.z_dim\n",
    "    Nx = pyro.sample(\"Nx\", dist.Uniform(torch.zeros(vae.image_dim), torch.ones(vae.image_dim)))\n",
    "    Nz = pyro.sample(\"Nz\", dist.Normal(torch.zeros(z_dim), torch.ones(z_dim)))\n",
    "    Ny = []\n",
    "    Y = []\n",
    "    ys = []\n",
    "    m = torch.distributions.gumbel.Gumbel(torch.tensor(0.0), torch.tensor(1.0))\n",
    "    for label_id in range(6):\n",
    "        name = vae.label_names[label_id]\n",
    "        length = vae.label_shape[label_id]\n",
    "        new = pyro.sample(\"Ny_%s\"%name, dist.Uniform(torch.zeros(length), torch.ones(length)) )\n",
    "        Ny.append(new)\n",
    "        gumbel_vars = torch.tensor([m.sample() for _ in range(length)])\n",
    "        max_ind = torch.argmax(torch.log(new) + gumbel_vars).item()\n",
    "        Y.append(pyro.sample(\"Y_%s\"%name, dist.Normal(torch.tensor(max_ind*1.0), 1e-4)))\n",
    "        ys.append(torch.nn.functional.one_hot(torch.tensor(max_ind), int(length)))\n",
    "                 \n",
    "    Y = torch.tensor(Y)\n",
    "    ys = torch.cat(ys).to(torch.float32).reshape(1,-1).cuda()\n",
    "    mu, sigma = vae.encoder.forward(xs, ys)\n",
    "    Z = pyro.sample(\"Z\", dist.Normal(mu.cpu() + Nz*sigma.cpu(), 1e-4))\n",
    "    zs = Z.cuda()\n",
    "    p = vae.decoder.forward(zs,ys).cpu()\n",
    "    X = pyro.sample(\"X\", dist.Normal((Nx < p).to(torch.float), 1e-4))\n",
    "    return X, Y, Z\n",
    "\n",
    "def generate_y_dict(label_names, y):\n",
    "    data = dict()\n",
    "    for i, name in enumerate(label_names):\n",
    "        data[\"Y_\"+name] = int(y[i]) \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = next(data_iter)\n",
    "x = xs[0].reshape(1,-1).cuda()\n",
    "y = ys[0].reshape(1,-1).cuda()\n",
    "\n",
    "x_, y_, z_ = SCM(vae, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  4., 19., 22., 24.]], device='cuda:0')\n",
      "tensor([ 0,  0,  4, 19, 22, 24])\n",
      "tensor([ 0,  0,  4, 19, 22, 24])\n",
      "tensor([ 0,  0,  4, 19, 22, 24])\n",
      "tensor([ 0,  0,  4, 19, 22, 24])\n",
      "tensor([ 0,  0,  4, 19, 22, 24])\n"
     ]
    }
   ],
   "source": [
    "data = generate_y_dict(vae.label_names, y.cpu()[0])\n",
    "cond_model = pyro.condition(SCM, data=data)\n",
    "print(y)\n",
    "N = 5\n",
    "result = np.zeros((100,64**2))\n",
    "for i in range(N):\n",
    "    ix,iy,_ = cond_model(vae, x)\n",
    "    result[i] = ix.cpu()\n",
    "    print(iy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer.importance import Importance\n",
    "from pyro.infer.mcmc import MCMC\n",
    "from pyro.infer.mcmc.nuts import HMC\n",
    "\n",
    "intervened_model = pyro.do(SCM, data={\"Y_shape\": torch.tensor(0.)})\n",
    "conditioned_model = pyro.condition(SCM, data={\"Y_shape\": torch.tensor(1.0)})\n",
    "\n",
    "posterior = pyro.infer.Importance(conditioned_model, num_samples = 1000)\n",
    "posterior.run(vae, x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posterior' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-591b88651e1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnoise_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Ny_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Nx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Nz'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'posterior' is not defined"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "result = np.zeros((N, vae.image_dim))\n",
    "for i in range(N):\n",
    "    trace = posterior()\n",
    "    data = dict()\n",
    "    noise_vars = ['Ny_' + s for s in vae.label_names] + ['Nx', 'Nz']\n",
    "    for name in noise_vars:\n",
    "        data[name] = trace.nodes[name]['value']\n",
    "        \n",
    "    con_obj = pyro.condition(intervened_model, data = data)\n",
    "    result[i] = con_obj(vae, x)[0]\n",
    "    \n",
    "# now generate density image\n",
    "density_comp(x, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_map(img):\n",
    "    dens_img = np.mean(img, axis=0).reshape(64,64)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(dens_img, interpolation='nearest', cmap=\"Greys_r\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "def density_comp(img, recons):\n",
    "    dens_img = np.mean(recons, axis=0).reshape(64,64)\n",
    "    fig = plt.figure()\n",
    "    fig.add_subplot(121)\n",
    "    plt.imshow(img.cpu().reshape(64,64), interpolation='nearest', cmap=\"Greys_r\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    fig.add_subplot(122)\n",
    "    plt.imshow(dens_img, interpolation='nearest', cmap=\"Greys_r\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
